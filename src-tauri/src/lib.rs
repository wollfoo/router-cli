use serde::{Deserialize, Serialize};
use std::sync::Mutex;
use tauri::{
    menu::{Menu, MenuItem},
    tray::{MouseButton, MouseButtonState, TrayIconBuilder, TrayIconEvent},
    Emitter, Manager, State,
};
use tauri_plugin_opener::OpenerExt;
use tauri_plugin_shell::process::CommandChild;
use tauri_plugin_shell::ShellExt;

// Proxy status structure
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProxyStatus {
    pub running: bool,
    pub port: u16,
    pub endpoint: String,
}

// Request log entry for live monitoring
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct RequestLog {
    pub id: String,
    pub timestamp: u64,
    pub provider: String,
    pub model: String,
    pub method: String,
    pub path: String,
    pub status: u16,
    pub duration_ms: u64,
    pub tokens_in: Option<u32>,
    pub tokens_out: Option<u32>,
}

impl Default for ProxyStatus {
    fn default() -> Self {
        Self {
            running: false,
            port: 8317,
            endpoint: "http://localhost:8317/v1".to_string(),
        }
    }
}

// Auth status for different providers
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AuthStatus {
    pub claude: bool,
    pub openai: bool,
    pub gemini: bool,
    pub qwen: bool,
    pub iflow: bool,
    pub vertex: bool,
    pub antigravity: bool,
}

impl Default for AuthStatus {
    fn default() -> Self {
        Self {
            claude: false,
            openai: false,
            gemini: false,
            qwen: false,
            iflow: false,
            vertex: false,
            antigravity: false,
        }
    }
}

// App configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct AppConfig {
    pub port: u16,
    pub auto_start: bool,
    pub launch_at_login: bool,
    #[serde(default)]
    pub debug: bool,
    #[serde(default)]
    pub proxy_url: String,
    #[serde(default)]
    pub request_retry: u16,
    #[serde(default)]
    pub quota_switch_project: bool,
    #[serde(default)]
    pub quota_switch_preview_model: bool,
    #[serde(default = "default_usage_stats_enabled")]
    pub usage_stats_enabled: bool,
    #[serde(default)]
    pub request_logging: bool,
    #[serde(default)]
    pub logging_to_file: bool,
    #[serde(default = "default_config_version")]
    pub config_version: u8,
}

fn default_usage_stats_enabled() -> bool {
    true
}

fn default_config_version() -> u8 {
    1
}

impl Default for AppConfig {
    fn default() -> Self {
        Self {
            port: 8317,
            auto_start: true,
            launch_at_login: false,
            debug: false,
            proxy_url: String::new(),
            request_retry: 0,
            quota_switch_project: false,
            quota_switch_preview_model: false,
            usage_stats_enabled: true,
            request_logging: false,
            logging_to_file: false,
            config_version: 1,
        }
    }
}


// OAuth state for tracking pending auth flows
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OAuthState {
    pub provider: String,
    pub state: String,
}

// Usage statistics from Management API
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
#[serde(rename_all = "camelCase")]
pub struct UsageStats {
    pub total_requests: u64,
    pub success_count: u64,
    pub failure_count: u64,
    pub total_tokens: u64,
    pub input_tokens: u64,
    pub output_tokens: u64,
    pub requests_today: u64,
    pub tokens_today: u64,
    #[serde(default)]
    pub models: Vec<ModelUsage>,
    /// Time-series data for charts
    #[serde(default)]
    pub requests_by_day: Vec<TimeSeriesPoint>,
    #[serde(default)]
    pub tokens_by_day: Vec<TimeSeriesPoint>,
    #[serde(default)]
    pub requests_by_hour: Vec<TimeSeriesPoint>,
    #[serde(default)]
    pub tokens_by_hour: Vec<TimeSeriesPoint>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct TimeSeriesPoint {
    pub label: String,
    pub value: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ModelUsage {
    pub model: String,
    pub requests: u64,
    pub tokens: u64,
}

// App state
pub struct AppState {
    pub proxy_status: Mutex<ProxyStatus>,
    pub auth_status: Mutex<AuthStatus>,
    pub config: Mutex<AppConfig>,
    pub pending_oauth: Mutex<Option<OAuthState>>,
    pub proxy_process: Mutex<Option<CommandChild>>,
}

impl Default for AppState {
    fn default() -> Self {
        Self {
            proxy_status: Mutex::new(ProxyStatus::default()),
            auth_status: Mutex::new(AuthStatus::default()),
            config: Mutex::new(AppConfig::default()),
            pending_oauth: Mutex::new(None),
            proxy_process: Mutex::new(None),
        }
    }
}

// Config file path
fn get_config_path() -> std::path::PathBuf {
    let config_dir = dirs::config_dir()
        .unwrap_or_else(|| std::path::PathBuf::from("."))
        .join("proxypal");
    std::fs::create_dir_all(&config_dir).ok();
    config_dir.join("config.json")
}

fn get_auth_path() -> std::path::PathBuf {
    let config_dir = dirs::config_dir()
        .unwrap_or_else(|| std::path::PathBuf::from("."))
        .join("proxypal");
    std::fs::create_dir_all(&config_dir).ok();
    config_dir.join("auth.json")
}

fn get_history_path() -> std::path::PathBuf {
    let config_dir = dirs::config_dir()
        .unwrap_or_else(|| std::path::PathBuf::from("."))
        .join("proxypal");
    std::fs::create_dir_all(&config_dir).ok();
    config_dir.join("history.json")
}

// Request history with metadata
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
#[serde(rename_all = "camelCase")]
pub struct RequestHistory {
    pub requests: Vec<RequestLog>,
    pub total_tokens_in: u64,
    pub total_tokens_out: u64,
    pub total_cost_usd: f64,
}

// Load request history from file
fn load_request_history() -> RequestHistory {
    let path = get_history_path();
    if path.exists() {
        if let Ok(data) = std::fs::read_to_string(&path) {
            if let Ok(history) = serde_json::from_str(&data) {
                return history;
            }
        }
    }
    RequestHistory::default()
}

// Save request history to file (keep last 100 requests)
fn save_request_history(history: &RequestHistory) -> Result<(), String> {
    let path = get_history_path();
    let mut trimmed = history.clone();
    // Keep only last 100 requests
    if trimmed.requests.len() > 100 {
        trimmed.requests = trimmed.requests.split_off(trimmed.requests.len() - 100);
    }
    let data = serde_json::to_string_pretty(&trimmed).map_err(|e| e.to_string())?;
    std::fs::write(path, data).map_err(|e| e.to_string())
}

// Estimate cost based on model and tokens
fn estimate_request_cost(model: &str, tokens_in: u32, tokens_out: u32) -> f64 {
    // Pricing per 1M tokens (input, output) - approximate as of 2024
    let (input_rate, output_rate) = match model.to_lowercase().as_str() {
        m if m.contains("claude-3-opus") => (15.0, 75.0),
        m if m.contains("claude-3-sonnet") || m.contains("claude-3.5-sonnet") => (3.0, 15.0),
        m if m.contains("claude-3-haiku") || m.contains("claude-3.5-haiku") => (0.25, 1.25),
        m if m.contains("gpt-4o") => (2.5, 10.0),
        m if m.contains("gpt-4-turbo") || m.contains("gpt-4") => (10.0, 30.0),
        m if m.contains("gpt-3.5") => (0.5, 1.5),
        m if m.contains("gemini-1.5-pro") => (1.25, 5.0),
        m if m.contains("gemini-1.5-flash") => (0.075, 0.30),
        m if m.contains("gemini-2") => (0.10, 0.40),
        m if m.contains("qwen") => (0.50, 2.0),
        _ => (1.0, 3.0), // Default conservative estimate
    };
    
    let input_cost = (tokens_in as f64 / 1_000_000.0) * input_rate;
    let output_cost = (tokens_out as f64 / 1_000_000.0) * output_rate;
    input_cost + output_cost
}

// Load config from file
fn load_config() -> AppConfig {
    let path = get_config_path();
    if path.exists() {
        if let Ok(data) = std::fs::read_to_string(&path) {
            if let Ok(config) = serde_json::from_str(&data) {
                return config;
            }
        }
    }
    AppConfig::default()
}

// Save config to file
fn save_config_to_file(config: &AppConfig) -> Result<(), String> {
    let path = get_config_path();
    let data = serde_json::to_string_pretty(config).map_err(|e| e.to_string())?;
    std::fs::write(path, data).map_err(|e| e.to_string())
}

// Load auth status from file
fn load_auth_status() -> AuthStatus {
    let path = get_auth_path();
    if path.exists() {
        if let Ok(data) = std::fs::read_to_string(&path) {
            if let Ok(auth) = serde_json::from_str(&data) {
                return auth;
            }
        }
    }
    AuthStatus::default()
}

// Save auth status to file
fn save_auth_to_file(auth: &AuthStatus) -> Result<(), String> {
    let path = get_auth_path();
    let data = serde_json::to_string_pretty(auth).map_err(|e| e.to_string())?;
    std::fs::write(path, data).map_err(|e| e.to_string())
}

// Detect provider from model name
fn detect_provider_from_model(model: &str) -> String {
    let model_lower = model.to_lowercase();
    
    if model_lower.contains("claude") || model_lower.contains("sonnet") || 
       model_lower.contains("opus") || model_lower.contains("haiku") {
        return "claude".to_string();
    }
    if model_lower.contains("gpt") || model_lower.contains("codex") || 
       model_lower.starts_with("o3") || model_lower.starts_with("o1") {
        return "openai".to_string();
    }
    if model_lower.contains("gemini") {
        return "gemini".to_string();
    }
    if model_lower.contains("qwen") {
        return "qwen".to_string();
    }
    if model_lower.contains("deepseek") {
        return "deepseek".to_string();
    }
    
    "unknown".to_string()
}

// Tauri commands
#[tauri::command]
fn get_proxy_status(state: State<AppState>) -> ProxyStatus {
    state.proxy_status.lock().unwrap().clone()
}

#[tauri::command]
async fn start_proxy(
    app: tauri::AppHandle,
    state: State<'_, AppState>,
) -> Result<ProxyStatus, String> {
    let config = state.config.lock().unwrap().clone();
    
    // Check if already running
    {
        let status = state.proxy_status.lock().unwrap();
        if status.running {
            return Ok(status.clone());
        }
    }

    // Create config directory and config file for CLIProxyAPI
    let config_dir = dirs::config_dir()
        .unwrap_or_else(|| std::path::PathBuf::from("."))
        .join("proxypal");
    std::fs::create_dir_all(&config_dir).map_err(|e| e.to_string())?;
    
    let proxy_config_path = config_dir.join("proxy-config.yaml");
    
    // Build proxy-url line if configured
    let proxy_url_line = if config.proxy_url.is_empty() {
        String::new()
    } else {
        format!("proxy-url: \"{}\"\n", config.proxy_url)
    };
    
    // Always regenerate config on start because CLIProxyAPI hashes the secret-key in place
    // and we need the plaintext key for Management API access
    let proxy_config = format!(
        r#"# ProxyPal generated config
port: {}
auth-dir: "~/.cli-proxy-api"
api-keys:
  - "proxypal-local"
debug: {}
usage-statistics-enabled: {}
logging-to-file: {}
request-retry: {}
{}
# Quota exceeded behavior
quota-exceeded:
  switch-project: {}
  switch-preview-model: {}

# Enable Management API for OAuth flows
remote-management:
  allow-remote: false
  secret-key: "proxypal-mgmt-key"
  disable-control-panel: true

# Amp CLI Integration - enables amp login and management routes
# See: https://help.router-for.me/agent-client/amp-cli.html
# Get API key from: https://ampcode.com/settings
ampcode:
  upstream-url: "https://ampcode.com"
  # upstream-api-key: "amp_..."  # Optional: set your Amp API key here if using API key auth
  restrict-management-to-localhost: true
"#,
        config.port,
        config.debug,
        config.usage_stats_enabled,
        config.logging_to_file,
        config.request_retry,
        proxy_url_line,
        config.quota_switch_project,
        config.quota_switch_preview_model
    );
    
    std::fs::write(&proxy_config_path, proxy_config).map_err(|e| e.to_string())?;

    // Spawn the sidecar process
    let sidecar = app
        .shell()
        .sidecar("cliproxyapi")
        .map_err(|e| format!("Failed to create sidecar command: {}", e))?
        .args(["--config", proxy_config_path.to_str().unwrap()]);

    let (mut rx, child) = sidecar.spawn().map_err(|e| format!("Failed to spawn sidecar: {}", e))?;

    // Store the child process
    {
        let mut process = state.proxy_process.lock().unwrap();
        *process = Some(child);
    }

    // Listen for stdout/stderr in a separate task (for logging only)
    let app_handle = app.clone();
    tauri::async_runtime::spawn(async move {
        use tauri_plugin_shell::process::CommandEvent;
        
        while let Some(event) = rx.recv().await {
            match event {
                CommandEvent::Stdout(line) => {
                    let text = String::from_utf8_lossy(&line);
                    println!("[CLIProxyAPI] {}", text);
                }
                CommandEvent::Stderr(line) => {
                    let text = String::from_utf8_lossy(&line);
                    eprintln!("[CLIProxyAPI ERROR] {}", text);
                }
                CommandEvent::Terminated(payload) => {
                    println!("[CLIProxyAPI] Process terminated: {:?}", payload);
                    // Update status when process dies unexpectedly
                    if let Some(state) = app_handle.try_state::<AppState>() {
                        let mut status = state.proxy_status.lock().unwrap();
                        status.running = false;
                        let _ = app_handle.emit("proxy-status-changed", status.clone());
                    }
                    break;
                }
                _ => {}
            }
        }
    });

    // Give it a moment to start
    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    
    // Sync usage statistics setting via Management API (in case it differs from config file)
    let port = config.port;
    let enable_url = format!("http://127.0.0.1:{}/v0/management/usage-statistics-enabled", port);
    let client = reqwest::Client::new();
    let _ = client
        .put(&enable_url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .json(&serde_json::json!({"value": config.usage_stats_enabled}))
        .send()
        .await;
    
    // Start background task to poll Management API for request details
    let app_handle2 = app.clone();
    tauri::async_runtime::spawn(async move {
        let client = reqwest::Client::new();
        let mut request_counter: u64 = 0;
        // Track seen timestamps per model to avoid duplicates
        let mut seen_timestamps: std::collections::HashSet<String> = std::collections::HashSet::new();
        
        loop {
            tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;
            
            // Check if still running
            if let Some(state) = app_handle2.try_state::<AppState>() {
                let running = state.proxy_status.lock().unwrap().running;
                if !running {
                    break;
                }
            } else {
                break;
            }
            
            // Fetch usage stats from Management API
            let url = format!("http://127.0.0.1:{}/v0/management/usage", port);
            if let Ok(response) = client
                .get(&url)
                .header("X-Management-Key", "proxypal-mgmt-key")
                .timeout(std::time::Duration::from_secs(3))
                .send()
                .await
            {
                if let Ok(json) = response.json::<serde_json::Value>().await {
                    if let Some(usage) = json.get("usage") {
                        // Parse and emit request events from the apis.models.details
                        if let Some(apis) = usage.get("apis").and_then(|v| v.as_object()) {
                            for (_api_key, api_data) in apis {
                                if let Some(models) = api_data.get("models").and_then(|v| v.as_object()) {
                                    for (model_name, model_data) in models {
                                        if let Some(details) = model_data.get("details").and_then(|v| v.as_array()) {
                                            for detail in details.iter() {
                                                // Use timestamp as unique key to deduplicate
                                                let ts_str = detail.get("timestamp")
                                                    .and_then(|v| v.as_str())
                                                    .unwrap_or("");
                                                
                                                // Create a unique key combining model + timestamp
                                                let unique_key = format!("{}:{}", model_name, ts_str);
                                                
                                                // Skip if we've already seen this request
                                                if seen_timestamps.contains(&unique_key) {
                                                    continue;
                                                }
                                                seen_timestamps.insert(unique_key);
                                                
                                                request_counter += 1;
                                                
                                                let timestamp = chrono::DateTime::parse_from_rfc3339(ts_str)
                                                    .map(|dt| dt.timestamp_millis() as u64)
                                                    .unwrap_or_else(|_| std::time::SystemTime::now()
                                                        .duration_since(std::time::UNIX_EPOCH)
                                                        .unwrap()
                                                        .as_millis() as u64);
                                                
                                                let tokens = detail.get("tokens");
                                                let input_tokens = tokens
                                                    .and_then(|t| t.get("input_tokens"))
                                                    .and_then(|v| v.as_u64())
                                                    .map(|v| v as u32);
                                                let output_tokens = tokens
                                                    .and_then(|t| t.get("output_tokens"))
                                                    .and_then(|v| v.as_u64())
                                                    .map(|v| v as u32);
                                                
                                                let failed = detail.get("failed")
                                                    .and_then(|v| v.as_bool())
                                                    .unwrap_or(false);
                                                
                                                // Detect provider from model name
                                                let provider = detect_provider_from_model(model_name);
                                                
                                                let log = RequestLog {
                                                    id: format!("req_{}", request_counter),
                                                    timestamp,
                                                    provider,
                                                    model: model_name.clone(),
                                                    method: "POST".to_string(),
                                                    path: "/v1/chat/completions".to_string(),
                                                    status: if failed { 500 } else { 200 },
                                                    duration_ms: 0, // Not available from usage API
                                                    tokens_in: input_tokens,
                                                    tokens_out: output_tokens,
                                                };
                                                
                                                let _ = app_handle2.emit("request-log", log);
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    });

    // Update status
    let new_status = {
        let mut status = state.proxy_status.lock().unwrap();
        status.running = true;
        status.port = config.port;
        status.endpoint = format!("http://localhost:{}/v1", config.port);
        status.clone()
    };

    // Emit status update
    let _ = app.emit("proxy-status-changed", new_status.clone());

    Ok(new_status)
}

#[tauri::command]
async fn stop_proxy(
    app: tauri::AppHandle,
    state: State<'_, AppState>,
) -> Result<ProxyStatus, String> {
    // Check if running
    {
        let status = state.proxy_status.lock().unwrap();
        if !status.running {
            return Ok(status.clone());
        }
    }

    // Kill the child process
    {
        let mut process = state.proxy_process.lock().unwrap();
        if let Some(child) = process.take() {
            child.kill().map_err(|e| format!("Failed to kill process: {}", e))?;
        }
    }

    // Update status
    let new_status = {
        let mut status = state.proxy_status.lock().unwrap();
        status.running = false;
        status.clone()
    };

    // Emit status update
    let _ = app.emit("proxy-status-changed", new_status.clone());

    Ok(new_status)
}

#[tauri::command]
fn get_auth_status(state: State<AppState>) -> AuthStatus {
    state.auth_status.lock().unwrap().clone()
}

// Compute usage statistics from local request history (persisted data)
// This ensures Analytics shows the same data as Dashboard's Request History
#[tauri::command]
fn get_usage_stats() -> UsageStats {
    let history = load_request_history();
    
    if history.requests.is_empty() {
        return UsageStats::default();
    }
    
    // Compute aggregate stats
    let total_requests = history.requests.len() as u64;
    let success_count = history.requests.iter().filter(|r| r.status < 400).count() as u64;
    let failure_count = total_requests - success_count;
    
    let input_tokens = history.total_tokens_in;
    let output_tokens = history.total_tokens_out;
    let total_tokens = input_tokens + output_tokens;
    
    // Get today's start timestamp for filtering
    let today_start = chrono::Local::now()
        .date_naive()
        .and_hms_opt(0, 0, 0)
        .unwrap()
        .and_local_timezone(chrono::Local)
        .unwrap()
        .timestamp_millis() as u64;
    
    // Compute today's stats
    let requests_today = history.requests.iter()
        .filter(|r| r.timestamp >= today_start)
        .count() as u64;
    
    let tokens_today: u64 = history.requests.iter()
        .filter(|r| r.timestamp >= today_start)
        .map(|r| (r.tokens_in.unwrap_or(0) + r.tokens_out.unwrap_or(0)) as u64)
        .sum();
    
    // Build time-series data (requests by day)
    let mut requests_by_day_map: std::collections::HashMap<String, u64> = std::collections::HashMap::new();
    let mut tokens_by_day_map: std::collections::HashMap<String, u64> = std::collections::HashMap::new();
    let mut requests_by_hour_map: std::collections::HashMap<String, u64> = std::collections::HashMap::new();
    let mut tokens_by_hour_map: std::collections::HashMap<String, u64> = std::collections::HashMap::new();
    
    for req in &history.requests {
        // Convert timestamp to datetime
        let dt = chrono::DateTime::from_timestamp_millis(req.timestamp as i64)
            .unwrap_or_else(|| chrono::Utc::now());
        let local_dt = dt.with_timezone(&chrono::Local);
        
        // Day key: YYYY-MM-DD
        let day_key = local_dt.format("%Y-%m-%d").to_string();
        *requests_by_day_map.entry(day_key.clone()).or_insert(0) += 1;
        let req_tokens = (req.tokens_in.unwrap_or(0) + req.tokens_out.unwrap_or(0)) as u64;
        *tokens_by_day_map.entry(day_key).or_insert(0) += req_tokens;
        
        // Hour key: YYYY-MM-DDTHH
        let hour_key = local_dt.format("%Y-%m-%dT%H").to_string();
        *requests_by_hour_map.entry(hour_key.clone()).or_insert(0) += 1;
        *tokens_by_hour_map.entry(hour_key).or_insert(0) += req_tokens;
    }
    
    // Convert maps to sorted vectors (oldest first)
    let mut requests_by_day: Vec<TimeSeriesPoint> = requests_by_day_map
        .into_iter()
        .map(|(label, value)| TimeSeriesPoint { label, value })
        .collect();
    requests_by_day.sort_by(|a, b| a.label.cmp(&b.label));
    // Keep last 14 days
    if requests_by_day.len() > 14 {
        requests_by_day = requests_by_day.split_off(requests_by_day.len() - 14);
    }
    
    let mut tokens_by_day: Vec<TimeSeriesPoint> = tokens_by_day_map
        .into_iter()
        .map(|(label, value)| TimeSeriesPoint { label, value })
        .collect();
    tokens_by_day.sort_by(|a, b| a.label.cmp(&b.label));
    if tokens_by_day.len() > 14 {
        tokens_by_day = tokens_by_day.split_off(tokens_by_day.len() - 14);
    }
    
    let mut requests_by_hour: Vec<TimeSeriesPoint> = requests_by_hour_map
        .into_iter()
        .map(|(label, value)| TimeSeriesPoint { label, value })
        .collect();
    requests_by_hour.sort_by(|a, b| a.label.cmp(&b.label));
    // Keep last 24 hours
    if requests_by_hour.len() > 24 {
        requests_by_hour = requests_by_hour.split_off(requests_by_hour.len() - 24);
    }
    
    let mut tokens_by_hour: Vec<TimeSeriesPoint> = tokens_by_hour_map
        .into_iter()
        .map(|(label, value)| TimeSeriesPoint { label, value })
        .collect();
    tokens_by_hour.sort_by(|a, b| a.label.cmp(&b.label));
    if tokens_by_hour.len() > 24 {
        tokens_by_hour = tokens_by_hour.split_off(tokens_by_hour.len() - 24);
    }
    
    // Build model usage stats
    let mut model_map: std::collections::HashMap<String, (u64, u64)> = std::collections::HashMap::new();
    for req in &history.requests {
        let entry = model_map.entry(req.model.clone()).or_insert((0, 0));
        entry.0 += 1; // requests
        entry.1 += (req.tokens_in.unwrap_or(0) + req.tokens_out.unwrap_or(0)) as u64; // tokens
    }
    
    let mut models: Vec<ModelUsage> = model_map
        .into_iter()
        .map(|(model, (requests, tokens))| ModelUsage { model, requests, tokens })
        .collect();
    models.sort_by(|a, b| b.requests.cmp(&a.requests));
    
    UsageStats {
        total_requests,
        success_count,
        failure_count,
        total_tokens,
        input_tokens,
        output_tokens,
        requests_today,
        tokens_today,
        models,
        requests_by_day,
        tokens_by_day,
        requests_by_hour,
        tokens_by_hour,
    }
}

// Get request history
#[tauri::command]
fn get_request_history() -> RequestHistory {
    load_request_history()
}

// Add a request to history (called when request-log event is emitted)
#[tauri::command]
fn add_request_to_history(request: RequestLog) -> Result<RequestHistory, String> {
    let mut history = load_request_history();
    
    // Calculate cost for this request
    let tokens_in = request.tokens_in.unwrap_or(0);
    let tokens_out = request.tokens_out.unwrap_or(0);
    let cost = estimate_request_cost(&request.model, tokens_in, tokens_out);
    
    // Update totals
    history.total_tokens_in += tokens_in as u64;
    history.total_tokens_out += tokens_out as u64;
    history.total_cost_usd += cost;
    
    // Add request
    history.requests.push(request);
    
    // Save
    save_request_history(&history)?;
    
    Ok(history)
}

// Clear request history
#[tauri::command]
fn clear_request_history() -> Result<(), String> {
    let history = RequestHistory::default();
    save_request_history(&history)
}

#[tauri::command]
async fn open_oauth(app: tauri::AppHandle, state: State<'_, AppState>, provider: String) -> Result<String, String> {
    // Get proxy port from config
    let port = {
        let config = state.config.lock().unwrap();
        config.port
    };

    // Get the OAuth URL from CLIProxyAPI's Management API
    // Add is_webui=true to use the embedded callback forwarder
    let endpoint = match provider.as_str() {
        "claude" => format!("http://localhost:{}/v0/management/anthropic-auth-url?is_webui=true", port),
        "openai" => format!("http://localhost:{}/v0/management/codex-auth-url?is_webui=true", port),
        "gemini" => format!("http://localhost:{}/v0/management/gemini-cli-auth-url?is_webui=true", port),
        "qwen" => format!("http://localhost:{}/v0/management/qwen-auth-url?is_webui=true", port),
        "iflow" => format!("http://localhost:{}/v0/management/iflow-auth-url?is_webui=true", port),
        "antigravity" => format!("http://localhost:{}/v0/management/antigravity-auth-url?is_webui=true", port),
        "vertex" => return Err("Vertex uses service account import, not OAuth. Use import_vertex_credential instead.".to_string()),
        _ => return Err(format!("Unknown provider: {}", provider)),
    };

    // Make HTTP request to get OAuth URL
    let client = reqwest::Client::new();
    let response = client
        .get(&endpoint)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .send()
        .await
        .map_err(|e| format!("Failed to get OAuth URL: {}. Is the proxy running?", e))?;

    if !response.status().is_success() {
        return Err(format!("Management API returned error: {}", response.status()));
    }

    // Parse response to get URL and state
    let body: serde_json::Value = response
        .json()
        .await
        .map_err(|e| format!("Failed to parse response: {}", e))?;

    let oauth_url = body["url"]
        .as_str()
        .ok_or("No URL in response")?
        .to_string();
    
    let oauth_state = body["state"]
        .as_str()
        .unwrap_or("")
        .to_string();

    // Store pending OAuth state
    {
        let mut pending = state.pending_oauth.lock().unwrap();
        *pending = Some(OAuthState {
            provider: provider.clone(),
            state: oauth_state.clone(),
        });
    }

    // Open the OAuth URL in the default browser
    app.opener()
        .open_url(&oauth_url, None::<&str>)
        .map_err(|e| e.to_string())?;

    // Return the state so frontend can poll for completion
    Ok(oauth_state)
}

#[tauri::command]
async fn poll_oauth_status(state: State<'_, AppState>, oauth_state: String) -> Result<bool, String> {
    let port = {
        let config = state.config.lock().unwrap();
        config.port
    };

    let endpoint = format!(
        "http://localhost:{}/v0/management/get-auth-status?state={}",
        port, oauth_state
    );

    let client = reqwest::Client::new();
    let response = client
        .get(&endpoint)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .send()
        .await
        .map_err(|e| format!("Failed to poll OAuth status: {}", e))?;

    if !response.status().is_success() {
        return Ok(false); // Not ready yet
    }

    let body: serde_json::Value = response
        .json()
        .await
        .map_err(|e| format!("Failed to parse response: {}", e))?;

    // Check if auth is complete - CLIProxyAPI returns { "status": "ok" } when done
    let status = body["status"].as_str().unwrap_or("wait");
    Ok(status == "ok")
}

#[tauri::command]
async fn refresh_auth_status(app: tauri::AppHandle, state: State<'_, AppState>) -> Result<AuthStatus, String> {
    // Check CLIProxyAPI's auth directory for credentials
    let auth_dir = dirs::home_dir()
        .unwrap_or_else(|| std::path::PathBuf::from("."))
        .join(".cli-proxy-api");

    let mut new_auth = AuthStatus::default();

    // Scan auth directory for credential files
    if let Ok(entries) = std::fs::read_dir(&auth_dir) {
        for entry in entries.flatten() {
            let filename = entry.file_name().to_string_lossy().to_lowercase();
            
            // CLIProxyAPI naming patterns:
            // - claude-{email}.json or anthropic-*.json
            // - codex-{email}.json
            // - gemini-{email}-{project}.json
            // - qwen-{email}.json
            // - iflow-{email}.json
            // - vertex-{project_id}.json
            // - antigravity-{email}.json
            
            if filename.ends_with(".json") {
                if filename.starts_with("claude-") || filename.starts_with("anthropic-") {
                    new_auth.claude = true;
                } else if filename.starts_with("codex-") {
                    new_auth.openai = true;
                } else if filename.starts_with("gemini-") {
                    new_auth.gemini = true;
                } else if filename.starts_with("qwen-") {
                    new_auth.qwen = true;
                } else if filename.starts_with("iflow-") {
                    new_auth.iflow = true;
                } else if filename.starts_with("vertex-") {
                    new_auth.vertex = true;
                } else if filename.starts_with("antigravity-") {
                    new_auth.antigravity = true;
                }
            }
        }
    }

    // Update state
    {
        let mut auth = state.auth_status.lock().unwrap();
        *auth = new_auth.clone();
    }

    // Save to our config
    save_auth_to_file(&new_auth)?;

    // Emit auth status update
    let _ = app.emit("auth-status-changed", new_auth.clone());

    Ok(new_auth)
}

#[tauri::command]
async fn complete_oauth(
    app: tauri::AppHandle,
    state: State<'_, AppState>,
    provider: String,
    code: String,
) -> Result<AuthStatus, String> {
    // In a real implementation, we would:
    // 1. Exchange the code for tokens
    // 2. Store the tokens securely (keychain/credential manager)
    // 3. Update the auth status
    let _ = code; // Mark as used

    // For now, just mark as authenticated
    {
        let mut auth = state.auth_status.lock().unwrap();
        match provider.as_str() {
            "claude" => auth.claude = true,
            "openai" => auth.openai = true,
            "gemini" => auth.gemini = true,
            "qwen" => auth.qwen = true,
            "iflow" => auth.iflow = true,
            "vertex" => auth.vertex = true,
            "antigravity" => auth.antigravity = true,
            _ => return Err(format!("Unknown provider: {}", provider)),
        }

        // Save to file
        save_auth_to_file(&auth)?;

        // Clear pending OAuth
        let mut pending = state.pending_oauth.lock().unwrap();
        *pending = None;

        // Emit auth status update
        let _ = app.emit("auth-status-changed", auth.clone());

        Ok(auth.clone())
    }
}

#[tauri::command]
async fn disconnect_provider(
    app: tauri::AppHandle,
    state: State<'_, AppState>,
    provider: String,
) -> Result<AuthStatus, String> {
    // Delete credential files from ~/.cli-proxy-api/ for this provider
    let auth_dir = dirs::home_dir()
        .unwrap_or_else(|| std::path::PathBuf::from("."))
        .join(".cli-proxy-api");
    
    if auth_dir.exists() {
        if let Ok(entries) = std::fs::read_dir(&auth_dir) {
            for entry in entries.flatten() {
                let filename = entry.file_name().to_string_lossy().to_lowercase();
                
                // Match credential files by provider prefix
                let should_delete = match provider.as_str() {
                    "claude" => filename.starts_with("claude-") || filename.starts_with("anthropic-"),
                    "openai" => filename.starts_with("codex-"),
                    "gemini" => filename.starts_with("gemini-"),
                    "qwen" => filename.starts_with("qwen-"),
                    "iflow" => filename.starts_with("iflow-"),
                    "vertex" => filename.starts_with("vertex-"),
                    "antigravity" => filename.starts_with("antigravity-"),
                    _ => false,
                };
                
                if should_delete && filename.ends_with(".json") {
                    if let Err(e) = std::fs::remove_file(entry.path()) {
                        eprintln!("Failed to delete credential file {:?}: {}", entry.path(), e);
                    }
                }
            }
        }
    }
    
    let mut auth = state.auth_status.lock().unwrap();

    match provider.as_str() {
        "claude" => auth.claude = false,
        "openai" => auth.openai = false,
        "gemini" => auth.gemini = false,
        "qwen" => auth.qwen = false,
        "iflow" => auth.iflow = false,
        "vertex" => auth.vertex = false,
        "antigravity" => auth.antigravity = false,
        _ => return Err(format!("Unknown provider: {}", provider)),
    }

    // Save to file
    save_auth_to_file(&auth)?;

    // Emit auth status update
    let _ = app.emit("auth-status-changed", auth.clone());

    Ok(auth.clone())
}

// Import Vertex service account credential (JSON file)
#[tauri::command]
async fn import_vertex_credential(
    app: tauri::AppHandle,
    state: State<'_, AppState>,
    file_path: String,
) -> Result<AuthStatus, String> {
    // Read the service account JSON file
    let content = std::fs::read_to_string(&file_path)
        .map_err(|e| format!("Failed to read file: {}", e))?;
    
    // Parse to validate it's valid JSON with required fields
    let json: serde_json::Value = serde_json::from_str(&content)
        .map_err(|e| format!("Invalid JSON: {}", e))?;
    
    // Check for required service account fields
    let project_id = json["project_id"]
        .as_str()
        .ok_or("Missing 'project_id' field in service account JSON")?;
    
    if json["type"].as_str() != Some("service_account") {
        return Err("Invalid service account: 'type' must be 'service_account'".to_string());
    }
    
    // Copy to CLIProxyAPI auth directory
    let auth_dir = dirs::home_dir()
        .unwrap_or_else(|| std::path::PathBuf::from("."))
        .join(".cli-proxy-api");
    
    std::fs::create_dir_all(&auth_dir).map_err(|e| e.to_string())?;
    
    let dest_path = auth_dir.join(format!("vertex-{}.json", project_id));
    std::fs::write(&dest_path, &content)
        .map_err(|e| format!("Failed to save credential: {}", e))?;
    
    // Update auth status
    let mut auth = state.auth_status.lock().unwrap();
    auth.vertex = true;
    
    // Save to file
    save_auth_to_file(&auth)?;
    
    // Emit auth status update
    let _ = app.emit("auth-status-changed", auth.clone());
    
    Ok(auth.clone())
}

#[tauri::command]
fn get_config(state: State<AppState>) -> AppConfig {
    state.config.lock().unwrap().clone()
}

#[tauri::command]
fn save_config(state: State<AppState>, config: AppConfig) -> Result<(), String> {
    let mut current_config = state.config.lock().unwrap();
    *current_config = config.clone();
    save_config_to_file(&config)
}

// Provider health status
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProviderHealth {
    pub claude: HealthStatus,
    pub openai: HealthStatus,
    pub gemini: HealthStatus,
    pub qwen: HealthStatus,
    pub iflow: HealthStatus,
    pub vertex: HealthStatus,
    pub antigravity: HealthStatus,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HealthStatus {
    pub status: String,  // "healthy", "degraded", "offline", "unconfigured"
    pub latency_ms: Option<u64>,
    pub last_checked: u64,
}

impl Default for HealthStatus {
    fn default() -> Self {
        Self {
            status: "unconfigured".to_string(),
            latency_ms: None,
            last_checked: 0,
        }
    }
}

#[tauri::command]
async fn check_provider_health(state: State<'_, AppState>) -> Result<ProviderHealth, String> {
    let config = state.config.lock().unwrap().clone();
    let auth = state.auth_status.lock().unwrap().clone();
    let proxy_running = state.proxy_status.lock().unwrap().running;
    
    let timestamp = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_secs();
    
    // If proxy isn't running, all providers are offline
    if !proxy_running {
        return Ok(ProviderHealth {
            claude: HealthStatus { status: "offline".to_string(), latency_ms: None, last_checked: timestamp },
            openai: HealthStatus { status: "offline".to_string(), latency_ms: None, last_checked: timestamp },
            gemini: HealthStatus { status: "offline".to_string(), latency_ms: None, last_checked: timestamp },
            qwen: HealthStatus { status: "offline".to_string(), latency_ms: None, last_checked: timestamp },
            iflow: HealthStatus { status: "offline".to_string(), latency_ms: None, last_checked: timestamp },
            vertex: HealthStatus { status: "offline".to_string(), latency_ms: None, last_checked: timestamp },
            antigravity: HealthStatus { status: "offline".to_string(), latency_ms: None, last_checked: timestamp },
        });
    }
    
    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(5))
        .build()
        .map_err(|e| e.to_string())?;
    
    let endpoint = format!("http://localhost:{}/v1/models", config.port);
    
    // Check proxy health by requesting models endpoint
    let start = std::time::Instant::now();
    let response = client.get(&endpoint)
        .header("Authorization", "Bearer proxypal-local")
        .send()
        .await;
    let latency = start.elapsed().as_millis() as u64;
    
    let proxy_healthy = response.map(|r| r.status().is_success()).unwrap_or(false);
    
    Ok(ProviderHealth {
        claude: if auth.claude && proxy_healthy {
            HealthStatus { status: "healthy".to_string(), latency_ms: Some(latency), last_checked: timestamp }
        } else if auth.claude {
            HealthStatus { status: "degraded".to_string(), latency_ms: None, last_checked: timestamp }
        } else {
            HealthStatus { status: "unconfigured".to_string(), latency_ms: None, last_checked: timestamp }
        },
        openai: if auth.openai && proxy_healthy {
            HealthStatus { status: "healthy".to_string(), latency_ms: Some(latency), last_checked: timestamp }
        } else if auth.openai {
            HealthStatus { status: "degraded".to_string(), latency_ms: None, last_checked: timestamp }
        } else {
            HealthStatus { status: "unconfigured".to_string(), latency_ms: None, last_checked: timestamp }
        },
        gemini: if auth.gemini && proxy_healthy {
            HealthStatus { status: "healthy".to_string(), latency_ms: Some(latency), last_checked: timestamp }
        } else if auth.gemini {
            HealthStatus { status: "degraded".to_string(), latency_ms: None, last_checked: timestamp }
        } else {
            HealthStatus { status: "unconfigured".to_string(), latency_ms: None, last_checked: timestamp }
        },
        qwen: if auth.qwen && proxy_healthy {
            HealthStatus { status: "healthy".to_string(), latency_ms: Some(latency), last_checked: timestamp }
        } else if auth.qwen {
            HealthStatus { status: "degraded".to_string(), latency_ms: None, last_checked: timestamp }
        } else {
            HealthStatus { status: "unconfigured".to_string(), latency_ms: None, last_checked: timestamp }
        },
        iflow: if auth.iflow && proxy_healthy {
            HealthStatus { status: "healthy".to_string(), latency_ms: Some(latency), last_checked: timestamp }
        } else if auth.iflow {
            HealthStatus { status: "degraded".to_string(), latency_ms: None, last_checked: timestamp }
        } else {
            HealthStatus { status: "unconfigured".to_string(), latency_ms: None, last_checked: timestamp }
        },
        vertex: if auth.vertex && proxy_healthy {
            HealthStatus { status: "healthy".to_string(), latency_ms: Some(latency), last_checked: timestamp }
        } else if auth.vertex {
            HealthStatus { status: "degraded".to_string(), latency_ms: None, last_checked: timestamp }
        } else {
            HealthStatus { status: "unconfigured".to_string(), latency_ms: None, last_checked: timestamp }
        },
        antigravity: if auth.antigravity && proxy_healthy {
            HealthStatus { status: "healthy".to_string(), latency_ms: Some(latency), last_checked: timestamp }
        } else if auth.antigravity {
            HealthStatus { status: "degraded".to_string(), latency_ms: None, last_checked: timestamp }
        } else {
            HealthStatus { status: "unconfigured".to_string(), latency_ms: None, last_checked: timestamp }
        },
    })
}

// Test agent connection by making a simple API call through the proxy
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct AgentTestResult {
    pub success: bool,
    pub message: String,
    pub latency_ms: Option<u64>,
}

#[tauri::command]
async fn test_agent_connection(state: State<'_, AppState>, agent_id: String) -> Result<AgentTestResult, String> {
    let config = state.config.lock().unwrap().clone();
    let proxy_running = state.proxy_status.lock().unwrap().running;
    
    if !proxy_running {
        return Ok(AgentTestResult {
            success: false,
            message: "Proxy is not running".to_string(),
            latency_ms: None,
        });
    }
    
    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(10))
        .build()
        .map_err(|e| e.to_string())?;
    
    // Use /v1/models endpoint for testing - lightweight and doesn't consume tokens
    let endpoint = format!("http://localhost:{}/v1/models", config.port);
    
    let start = std::time::Instant::now();
    let response = client.get(&endpoint)
        .header("Authorization", "Bearer proxypal-local")
        .send()
        .await;
    let latency = start.elapsed().as_millis() as u64;
    
    match response {
        Ok(resp) => {
            if resp.status().is_success() {
                Ok(AgentTestResult {
                    success: true,
                    message: format!("Connection successful! {} is ready to use.", agent_id),
                    latency_ms: Some(latency),
                })
            } else {
                Ok(AgentTestResult {
                    success: false,
                    message: format!("Proxy returned status {}", resp.status()),
                    latency_ms: Some(latency),
                })
            }
        }
        Err(e) => {
            Ok(AgentTestResult {
                success: false,
                message: format!("Connection failed: {}", e),
                latency_ms: None,
            })
        }
    }
}

// Get available models from CLIProxyAPI /v1/models endpoint
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct AvailableModel {
    pub id: String,
    pub owned_by: String,
}

#[derive(Debug, Deserialize)]
struct ModelsApiResponse {
    data: Vec<ModelsApiModel>,
}

#[derive(Debug, Deserialize)]
struct ModelsApiModel {
    id: String,
    owned_by: String,
}

#[tauri::command]
async fn get_available_models(state: State<'_, AppState>) -> Result<Vec<AvailableModel>, String> {
    let config = state.config.lock().unwrap().clone();
    let proxy_running = state.proxy_status.lock().unwrap().running;
    
    if !proxy_running {
        return Ok(vec![]);
    }
    
    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(10))
        .build()
        .map_err(|e| e.to_string())?;
    
    let endpoint = format!("http://localhost:{}/v1/models", config.port);
    
    let response = match client.get(&endpoint)
        .header("Authorization", "Bearer proxypal-local")
        .send()
        .await
    {
        Ok(resp) => resp,
        Err(e) => {
            // Connection error - proxy might have crashed
            // Update state to reflect proxy is not running
            {
                let mut status = state.proxy_status.lock().unwrap();
                status.running = false;
            }
            return Err(format!("Proxy not responding. Please restart the proxy. ({})", e));
        }
    };
    
    if !response.status().is_success() {
        return Err(format!("API returned status {}", response.status()));
    }
    
    let api_response: ModelsApiResponse = response
        .json()
        .await
        .map_err(|e| format!("Failed to parse models response: {}", e))?;
    
    let models: Vec<AvailableModel> = api_response.data
        .into_iter()
        .map(|m| AvailableModel {
            id: m.id,
            owned_by: m.owned_by,
        })
        .collect();
    
    Ok(models)
}

// Handle deep link OAuth callback
fn handle_deep_link(app: &tauri::AppHandle, urls: Vec<url::Url>) {
    for url in urls {
        if url.scheme() == "proxypal" && url.path() == "/oauth/callback" {
            // Parse query parameters
            let params: std::collections::HashMap<_, _> = url.query_pairs().collect();

            if let (Some(code), Some(state)) = (params.get("code"), params.get("state")) {
                // Verify state and get provider from pending OAuth
                let app_state = app.state::<AppState>();
                let pending = app_state.pending_oauth.lock().unwrap().clone();

                if let Some(oauth) = pending {
                    if oauth.state == state.as_ref() {
                        // Emit event to frontend
                        let _ = app.emit(
                            "oauth-callback",
                            serde_json::json!({
                                "provider": oauth.provider,
                                "code": code.as_ref()
                            }),
                        );
                    }
                }
            }

            // Bring window to front
            if let Some(window) = app.get_webview_window("main") {
                let _ = window.unminimize();
                let _ = window.show();
                let _ = window.set_focus();
            }
        }
    }
}

// Setup system tray
fn setup_tray(app: &tauri::App) -> Result<(), Box<dyn std::error::Error>> {
    let toggle_item = MenuItem::with_id(app, "toggle", "Toggle Proxy", true, None::<&str>)?;
    let dashboard_item = MenuItem::with_id(app, "dashboard", "Open Dashboard", true, None::<&str>)?;
    let quit_item = MenuItem::with_id(app, "quit", "Quit ProxyPal", true, None::<&str>)?;

    let menu = Menu::with_items(app, &[&toggle_item, &dashboard_item, &quit_item])?;

    let _tray = TrayIconBuilder::new()
        .icon(app.default_window_icon().unwrap().clone())
        .menu(&menu)
        .show_menu_on_left_click(false)
        .tooltip("ProxyPal - Proxy stopped")
        .on_menu_event(move |app, event| match event.id.as_ref() {
            "toggle" => {
                let app_state = app.state::<AppState>();
                let is_running = app_state.proxy_status.lock().unwrap().running;

                // Emit toggle event to frontend
                let _ = app.emit("tray-toggle-proxy", !is_running);
            }
            "dashboard" => {
                if let Some(window) = app.get_webview_window("main") {
                    let _ = window.unminimize();
                    let _ = window.show();
                    let _ = window.set_focus();
                }
            }
            "quit" => {
                app.exit(0);
            }
            _ => {}
        })
        .on_tray_icon_event(|tray, event| {
            if let TrayIconEvent::Click {
                button: MouseButton::Left,
                button_state: MouseButtonState::Up,
                ..
            } = event
            {
                let app = tray.app_handle();
                if let Some(window) = app.get_webview_window("main") {
                    let _ = window.unminimize();
                    let _ = window.show();
                    let _ = window.set_focus();
                }
            }
        })
        .build(app)?;

    Ok(())
}

// Detected AI coding tool
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct DetectedTool {
    pub id: String,
    pub name: String,
    pub installed: bool,
    pub config_path: Option<String>,
    pub can_auto_configure: bool,
}

// CLI Agent configuration status
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct AgentStatus {
    pub id: String,
    pub name: String,
    pub description: String,
    pub installed: bool,
    pub configured: bool,
    pub config_type: String,  // "env", "file", "both"
    pub config_path: Option<String>,
    pub logo: String,
    pub docs_url: String,
}

// Detect installed CLI agents
#[tauri::command]
fn detect_cli_agents(state: State<AppState>) -> Vec<AgentStatus> {
    let home = dirs::home_dir().unwrap_or_default();
    let config = state.config.lock().unwrap();
    let endpoint = format!("http://127.0.0.1:{}", config.port);
    let mut agents = Vec::new();
    
    // 1. Claude Code - uses environment variables
    // Check if claude/claude-code binary exists
    let claude_installed = which_exists("claude");
    let claude_configured = check_env_configured("ANTHROPIC_BASE_URL", &endpoint);
    
    agents.push(AgentStatus {
        id: "claude-code".to_string(),
        name: "Claude Code".to_string(),
        description: "Anthropic's official CLI for Claude models".to_string(),
        installed: claude_installed,
        configured: claude_configured,
        config_type: "env".to_string(),
        config_path: None,
        logo: "/logos/claude.svg".to_string(),
        docs_url: "https://help.router-for.me/agent-client/claude-code.html".to_string(),
    });
    
    // 2. Codex - uses ~/.codex/config.toml and ~/.codex/auth.json
    let codex_installed = which_exists("codex");
    let codex_config = home.join(".codex/config.toml");
    let codex_configured = if codex_config.exists() {
        std::fs::read_to_string(&codex_config)
            .map(|c| c.contains("cliproxyapi") || c.contains(&endpoint))
            .unwrap_or(false)
    } else {
        false
    };
    
    agents.push(AgentStatus {
        id: "codex".to_string(),
        name: "Codex CLI".to_string(),
        description: "OpenAI's Codex CLI for GPT-5 models".to_string(),
        installed: codex_installed,
        configured: codex_configured,
        config_type: "file".to_string(),
        config_path: Some(codex_config.to_string_lossy().to_string()),
        logo: "/logos/openai.svg".to_string(),
        docs_url: "https://help.router-for.me/agent-client/codex.html".to_string(),
    });
    
    // 3. Gemini CLI - uses environment variables
    let gemini_installed = which_exists("gemini");
    let gemini_configured = check_env_configured("CODE_ASSIST_ENDPOINT", &endpoint) 
        || check_env_configured("GOOGLE_GEMINI_BASE_URL", &endpoint);
    
    agents.push(AgentStatus {
        id: "gemini-cli".to_string(),
        name: "Gemini CLI".to_string(),
        description: "Google's Gemini CLI for Gemini models".to_string(),
        installed: gemini_installed,
        configured: gemini_configured,
        config_type: "env".to_string(),
        config_path: None,
        logo: "/logos/gemini.svg".to_string(),
        docs_url: "https://help.router-for.me/agent-client/gemini-cli.html".to_string(),
    });
    
    // 4. Factory Droid - uses ~/.factory/config.json
    let droid_installed = which_exists("droid") || which_exists("factory");
    let droid_config = home.join(".factory/config.json");
    let droid_configured = if droid_config.exists() {
        std::fs::read_to_string(&droid_config)
            .map(|c| c.contains(&endpoint) || c.contains("127.0.0.1:8317"))
            .unwrap_or(false)
    } else {
        false
    };
    
    agents.push(AgentStatus {
        id: "factory-droid".to_string(),
        name: "Factory Droid".to_string(),
        description: "Factory's AI coding agent".to_string(),
        installed: droid_installed,
        configured: droid_configured,
        config_type: "file".to_string(),
        config_path: Some(droid_config.to_string_lossy().to_string()),
        logo: "/logos/droid.svg".to_string(),
        docs_url: "https://help.router-for.me/agent-client/droid.html".to_string(),
    });
    
    // 5. Amp CLI - uses ~/.config/amp/settings.json or AMP_URL env
    let amp_installed = which_exists("amp");
    let amp_config = home.join(".config/amp/settings.json");
    let amp_configured = check_env_configured("AMP_URL", &endpoint) || {
        if amp_config.exists() {
            std::fs::read_to_string(&amp_config)
                .map(|c| c.contains(&endpoint) || c.contains("localhost:8317"))
                .unwrap_or(false)
        } else {
            false
        }
    };
    
    agents.push(AgentStatus {
        id: "amp-cli".to_string(),
        name: "Amp CLI".to_string(),
        description: "Sourcegraph's Amp coding assistant".to_string(),
        installed: amp_installed,
        configured: amp_configured,
        config_type: "both".to_string(),
        config_path: Some(amp_config.to_string_lossy().to_string()),
        logo: "/logos/amp.svg".to_string(),
        docs_url: "https://help.router-for.me/agent-client/amp-cli.html".to_string(),
    });
    
    // 6. OpenCode - uses opencode.json config file with custom provider
    let opencode_installed = which_exists("opencode");
    // Check for global opencode.json in ~/.config/opencode/opencode.json
    let opencode_global_config = home.join(".config/opencode/opencode.json");
    let opencode_configured = if opencode_global_config.exists() {
        // Check if our proxypal provider is configured
        std::fs::read_to_string(&opencode_global_config)
            .map(|content| content.contains("proxypal") && content.contains(&endpoint))
            .unwrap_or(false)
    } else {
        false
    };
    
    agents.push(AgentStatus {
        id: "opencode".to_string(),
        name: "OpenCode".to_string(),
        description: "Terminal-based AI coding assistant".to_string(),
        installed: opencode_installed,
        configured: opencode_configured,
        config_type: "config".to_string(),
        config_path: Some(opencode_global_config.to_string_lossy().to_string()),
        logo: "/logos/opencode.svg".to_string(),
        docs_url: "https://opencode.ai/docs/providers/".to_string(),
    });
    
    agents
}

// Helper to check if a command exists by checking common installation paths
// Note: Using `which` command doesn't work in production builds (sandboxed macOS app)
// so we check common binary locations directly
fn which_exists(cmd: &str) -> bool {
    let home = dirs::home_dir().unwrap_or_default();
    
    // Common binary installation paths (static)
    let mut paths = vec![
        // Homebrew (Apple Silicon)
        std::path::PathBuf::from("/opt/homebrew/bin"),
        // Homebrew (Intel) / system
        std::path::PathBuf::from("/usr/local/bin"),
        // System binaries
        std::path::PathBuf::from("/usr/bin"),
        // Cargo (Rust)
        home.join(".cargo/bin"),
        // npm global (default)
        home.join(".npm-global/bin"),
        // npm global (alternative)
        std::path::PathBuf::from("/usr/local/lib/node_modules/.bin"),
        // Local bin
        home.join(".local/bin"),
        // Go binaries
        home.join("go/bin"),
        // Bun binaries
        home.join(".bun/bin"),
    ];
    
    // Add NVM node versions - scan for installed node versions
    let nvm_dir = home.join(".nvm/versions/node");
    if nvm_dir.exists() {
        if let Ok(entries) = std::fs::read_dir(&nvm_dir) {
            for entry in entries.flatten() {
                let bin_path = entry.path().join("bin");
                if bin_path.exists() {
                    paths.push(bin_path);
                }
            }
        }
    }
    
    // Check all paths
    for path in &paths {
        if path.join(cmd).exists() {
            return true;
        }
    }
    
    false
}

// Helper to check if env var is set to expected value
fn check_env_configured(var: &str, expected_prefix: &str) -> bool {
    std::env::var(var)
        .map(|v| v.starts_with(expected_prefix))
        .unwrap_or(false)
}

// Get model context/output limits based on model ID and provider
fn get_model_limits(model_id: &str, owned_by: &str) -> (u64, u64) {
    // Return (context_limit, output_limit)
    match owned_by {
        "anthropic" => {
            if model_id.contains("opus") {
                (200000, 16384)
            } else if model_id.contains("haiku") {
                (200000, 8192)
            } else {
                (200000, 16384) // sonnet default
            }
        }
        "google" => {
            // Gemini models have huge context
            (1000000, 65536)
        }
        "openai" => {
            if model_id.contains("o3") || model_id.contains("o1") {
                (200000, 100000)
            } else {
                (128000, 32768)
            }
        }
        "qwen" => (131072, 16384),
        "deepseek" => (64000, 8192),
        _ => (128000, 16384) // safe defaults
    }
}

// Get display name for a model
fn get_model_display_name(model_id: &str, owned_by: &str) -> String {
    // Convert model ID to human-readable name
    let base_name = model_id
        .replace("-", " ")
        .replace(".", " ")
        .split_whitespace()
        .map(|word| {
            let mut chars: Vec<char> = word.chars().collect();
            if !chars.is_empty() {
                chars[0] = chars[0].to_uppercase().next().unwrap_or(chars[0]);
            }
            chars.into_iter().collect::<String>()
        })
        .collect::<Vec<String>>()
        .join(" ");
    
    // Add provider prefix for clarity
    match owned_by {
        "anthropic" => format!("{}", base_name),
        "google" => format!("{}", base_name),
        "openai" => format!("{}", base_name),
        "qwen" => format!("{}", base_name),
        _ => base_name
    }
}

// Configure a CLI agent with ProxyPal
#[tauri::command]
fn configure_cli_agent(state: State<AppState>, agent_id: String, models: Vec<AvailableModel>) -> Result<serde_json::Value, String> {
    let config = state.config.lock().unwrap();
    let port = config.port;
    let endpoint = format!("http://127.0.0.1:{}", port);
    let endpoint_v1 = format!("{}/v1", endpoint);
    let home = dirs::home_dir().ok_or("Could not find home directory")?;
    
    match agent_id.as_str() {
        "claude-code" => {
            // Generate shell config for Claude Code
            let shell_config = format!(r#"# ProxyPal - Claude Code Configuration
export ANTHROPIC_BASE_URL="{}"
export ANTHROPIC_AUTH_TOKEN="proxypal-local"
# For Claude Code 2.x
export ANTHROPIC_DEFAULT_OPUS_MODEL="claude-opus-4-1-20250805"
export ANTHROPIC_DEFAULT_SONNET_MODEL="claude-sonnet-4-5-20250929"
export ANTHROPIC_DEFAULT_HAIKU_MODEL="claude-3-5-haiku-20241022"
# For Claude Code 1.x
export ANTHROPIC_MODEL="claude-sonnet-4-5-20250929"
export ANTHROPIC_SMALL_FAST_MODEL="claude-3-5-haiku-20241022"
"#, endpoint);
            
            Ok(serde_json::json!({
                "success": true,
                "configType": "env",
                "shellConfig": shell_config,
                "instructions": "Add the above to your ~/.bashrc, ~/.zshrc, or shell config file, then restart your terminal."
            }))
        },
        
        "codex" => {
            // Create ~/.codex directory
            let codex_dir = home.join(".codex");
            std::fs::create_dir_all(&codex_dir).map_err(|e| e.to_string())?;
            
            // Write config.toml
            let config_content = format!(r#"# ProxyPal - Codex Configuration
model_provider = "cliproxyapi"
model = "gpt-5-codex"
model_reasoning_effort = "high"

[model_providers.cliproxyapi]
name = "cliproxyapi"
base_url = "{}/v1"
wire_api = "responses"
"#, endpoint);
            
            let config_path = codex_dir.join("config.toml");
            std::fs::write(&config_path, &config_content).map_err(|e| e.to_string())?;
            
            // Write auth.json
            let auth_content = r#"{
  "OPENAI_API_KEY": "proxypal-local"
}"#;
            let auth_path = codex_dir.join("auth.json");
            std::fs::write(&auth_path, auth_content).map_err(|e| e.to_string())?;
            
            Ok(serde_json::json!({
                "success": true,
                "configType": "file",
                "configPath": config_path.to_string_lossy(),
                "authPath": auth_path.to_string_lossy(),
                "instructions": "Codex has been configured. Run 'codex' to start using it."
            }))
        },
        
        "gemini-cli" => {
            // Generate shell config for Gemini CLI
            let shell_config = format!(r#"# ProxyPal - Gemini CLI Configuration
# Option 1: OAuth mode (local only)
export CODE_ASSIST_ENDPOINT="{}"

# Option 2: API Key mode (works with any IP/domain)
# export GOOGLE_GEMINI_BASE_URL="{}"
# export GEMINI_API_KEY="proxypal-local"
"#, endpoint, endpoint);
            
            Ok(serde_json::json!({
                "success": true,
                "configType": "env",
                "shellConfig": shell_config,
                "instructions": "Add the above to your ~/.bashrc, ~/.zshrc, or shell config file, then restart your terminal."
            }))
        },
        
        "factory-droid" => {
            // Create ~/.factory directory
            let factory_dir = home.join(".factory");
            std::fs::create_dir_all(&factory_dir).map_err(|e| e.to_string())?;
            
            // Build dynamic custom_models array from available models
            let custom_models: Vec<serde_json::Value> = models.iter().map(|m| {
                let (base_url, provider) = match m.owned_by.as_str() {
                    "anthropic" => (endpoint.clone(), "anthropic"),
                    _ => (format!("{}/v1", endpoint), "openai"),
                };
                serde_json::json!({
                    "model": m.id,
                    "base_url": base_url,
                    "api_key": "proxypal-local",
                    "provider": provider
                })
            }).collect();
            
            let config_json = serde_json::json!({
                "custom_models": custom_models
            });
            
            let config_path = factory_dir.join("config.json");
            let config_str = serde_json::to_string_pretty(&config_json).map_err(|e| e.to_string())?;
            std::fs::write(&config_path, &config_str).map_err(|e| e.to_string())?;
            
            Ok(serde_json::json!({
                "success": true,
                "configType": "file",
                "configPath": config_path.to_string_lossy(),
                "modelsConfigured": models.len(),
                "instructions": "Factory Droid has been configured. Run 'droid' or 'factory' to start using it."
            }))
        },
        
        "amp-cli" => {
            // Create ~/.config/amp directory
            let amp_dir = home.join(".config/amp");
            std::fs::create_dir_all(&amp_dir).map_err(|e| e.to_string())?;
            
            // Amp CLI requires localhost URL (not 127.0.0.1) per CLIProxyAPI docs
            // See: https://help.router-for.me/agent-client/amp-cli.html
            let amp_endpoint = format!("http://localhost:{}", port);
            
            // Write settings.json - amp.url is the only required setting
            let settings_content = format!(r#"{{
  "amp.url": "{}"
}}"#, amp_endpoint);
            
            let config_path = amp_dir.join("settings.json");
            std::fs::write(&config_path, &settings_content).map_err(|e| e.to_string())?;
            
            // Also provide env var option and API key instructions
            let shell_config = format!(r#"# ProxyPal - Amp CLI Configuration (alternative to settings.json)
export AMP_URL="{}"

# For non-interactive use (CI/CD), set your API key from https://ampcode.com/settings
# export AMP_API_KEY="amp_..."
"#, amp_endpoint);
            
            Ok(serde_json::json!({
                "success": true,
                "configType": "both",
                "configPath": config_path.to_string_lossy(),
                "shellConfig": shell_config,
                "instructions": "Amp CLI has been configured. Run 'amp login' to authenticate (opens browser), then 'amp' to start using it. For API key auth, get your key from https://ampcode.com/settings"
            }))
        },
        
        "opencode" => {
            // OpenCode uses opencode.json config file with custom provider
            // See: https://opencode.ai/docs/providers/#custom-provider
            let config_dir = home.join(".config/opencode");
            std::fs::create_dir_all(&config_dir).map_err(|e| e.to_string())?;
            let config_path = config_dir.join("opencode.json");
            
            // Build dynamic models object from available models
            // OpenCode needs model configs with name and limits
            let mut models_obj = serde_json::Map::new();
            for m in &models {
                let (context_limit, output_limit) = get_model_limits(&m.id, &m.owned_by);
                let display_name = get_model_display_name(&m.id, &m.owned_by);
                models_obj.insert(m.id.clone(), serde_json::json!({
                    "name": display_name,
                    "limit": { "context": context_limit, "output": output_limit }
                }));
            }
            
            // Create or update opencode.json with proxypal provider
            let opencode_config = serde_json::json!({
                "$schema": "https://opencode.ai/config.json",
                "provider": {
                    "proxypal": {
                        "npm": "@ai-sdk/openai-compatible",
                        "name": "ProxyPal (Local Proxy)",
                        "options": {
                            "baseURL": endpoint_v1,
                            "apiKey": "proxypal-local"
                        },
                        "models": models_obj
                    }
                }
            });
            
            // If config exists, merge with existing
            let final_config = if config_path.exists() {
                if let Ok(existing) = std::fs::read_to_string(&config_path) {
                    if let Ok(mut existing_json) = serde_json::from_str::<serde_json::Value>(&existing) {
                        // Merge provider into existing config
                        if let Some(providers) = existing_json.get_mut("provider") {
                            if let Some(obj) = providers.as_object_mut() {
                                obj.insert("proxypal".to_string(), opencode_config["provider"]["proxypal"].clone());
                            }
                        } else {
                            existing_json["provider"] = opencode_config["provider"].clone();
                        }
                        existing_json
                    } else {
                        opencode_config
                    }
                } else {
                    opencode_config
                }
            } else {
                opencode_config
            };
            
            let config_str = serde_json::to_string_pretty(&final_config).map_err(|e| e.to_string())?;
            std::fs::write(&config_path, &config_str).map_err(|e| e.to_string())?;
            
            Ok(serde_json::json!({
                "success": true,
                "configType": "config",
                "configPath": config_path.to_string_lossy(),
                "modelsConfigured": models.len(),
                "instructions": "ProxyPal provider added to OpenCode. Run 'opencode' and use /models to select a model (e.g., proxypal/gemini-2.5-pro). OpenCode uses AI SDK (ai-sdk.dev) and models.dev registry."
            }))
        },
        
        _ => Err(format!("Unknown agent: {}", agent_id)),
    }
}

// Get shell profile path
#[tauri::command]
fn get_shell_profile_path() -> Result<String, String> {
    let home = dirs::home_dir().ok_or("Could not find home directory")?;
    
    // Check for common shell config files
    let shell = std::env::var("SHELL").unwrap_or_default();
    
    let profile_path = if shell.contains("zsh") {
        home.join(".zshrc")
    } else if shell.contains("bash") {
        // Prefer .bashrc on Linux, .bash_profile on macOS
        #[cfg(target_os = "macos")]
        let path = home.join(".bash_profile");
        #[cfg(not(target_os = "macos"))]
        let path = home.join(".bashrc");
        path
    } else if shell.contains("fish") {
        home.join(".config/fish/config.fish")
    } else {
        // Default to .profile
        home.join(".profile")
    };
    
    Ok(profile_path.to_string_lossy().to_string())
}

// Append environment config to shell profile
#[tauri::command]
fn append_to_shell_profile(content: String) -> Result<String, String> {
    let profile_path = get_shell_profile_path()?;
    let path = std::path::Path::new(&profile_path);
    
    // Read existing content
    let existing = std::fs::read_to_string(path).unwrap_or_default();
    
    // Check if ProxyPal config already exists
    if existing.contains("# ProxyPal") {
        return Err("ProxyPal configuration already exists in shell profile. Please remove it first or update manually.".to_string());
    }
    
    // Append new config
    let new_content = format!("{}\n\n{}", existing.trim_end(), content);
    std::fs::write(path, new_content).map_err(|e| e.to_string())?;
    
    Ok(profile_path)
}

// Detect installed AI coding tools
#[tauri::command]
fn detect_ai_tools() -> Vec<DetectedTool> {
    let home = dirs::home_dir().unwrap_or_default();
    let mut tools = Vec::new();
    
    // Check for Cursor
    #[cfg(target_os = "macos")]
    let cursor_app = std::path::Path::new("/Applications/Cursor.app").exists();
    #[cfg(target_os = "windows")]
    let cursor_app = dirs::data_local_dir()
        .map(|p| p.join("Programs/cursor/Cursor.exe").exists())
        .unwrap_or(false);
    #[cfg(target_os = "linux")]
    let cursor_app = home.join(".local/share/applications/cursor.desktop").exists() 
        || std::path::Path::new("/usr/share/applications/cursor.desktop").exists();
    
    tools.push(DetectedTool {
        id: "cursor".to_string(),
        name: "Cursor".to_string(),
        installed: cursor_app,
        config_path: None, // Cursor doesn't support custom API base URL
        can_auto_configure: false,
    });
    
    // Check for VS Code (needed for Continue/Cline)
    #[cfg(target_os = "macos")]
    let vscode_installed = std::path::Path::new("/Applications/Visual Studio Code.app").exists();
    #[cfg(target_os = "windows")]
    let vscode_installed = dirs::data_local_dir()
        .map(|p| p.join("Programs/Microsoft VS Code/Code.exe").exists())
        .unwrap_or(false);
    #[cfg(target_os = "linux")]
    let vscode_installed = std::path::Path::new("/usr/bin/code").exists();
    
    // Check for Continue extension (config file)
    let continue_config = home.join(".continue");
    let continue_yaml = continue_config.join("config.yaml");
    let continue_json = continue_config.join("config.json");
    let continue_installed = continue_yaml.exists() || continue_json.exists() || continue_config.exists();
    
    tools.push(DetectedTool {
        id: "continue".to_string(),
        name: "Continue".to_string(),
        installed: continue_installed || vscode_installed,
        config_path: if continue_yaml.exists() {
            Some(continue_yaml.to_string_lossy().to_string())
        } else if continue_json.exists() {
            Some(continue_json.to_string_lossy().to_string())
        } else {
            Some(continue_yaml.to_string_lossy().to_string()) // Default to yaml
        },
        can_auto_configure: true, // Continue has editable config
    });
    
    // Check for Cline extension
    #[cfg(target_os = "macos")]
    let cline_storage = home.join("Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev");
    #[cfg(target_os = "windows")]
    let cline_storage = dirs::data_dir()
        .map(|p| p.join("Code/User/globalStorage/saoudrizwan.claude-dev"))
        .unwrap_or_default();
    #[cfg(target_os = "linux")]
    let cline_storage = home.join(".config/Code/User/globalStorage/saoudrizwan.claude-dev");
    
    tools.push(DetectedTool {
        id: "cline".to_string(),
        name: "Cline".to_string(),
        installed: cline_storage.exists() || vscode_installed,
        config_path: None, // Cline uses VS Code settings UI
        can_auto_configure: false,
    });
    
    // Check for Windsurf
    #[cfg(target_os = "macos")]
    let windsurf_app = std::path::Path::new("/Applications/Windsurf.app").exists();
    #[cfg(target_os = "windows")]
    let windsurf_app = dirs::data_local_dir()
        .map(|p| p.join("Programs/Windsurf/Windsurf.exe").exists())
        .unwrap_or(false);
    #[cfg(target_os = "linux")]
    let windsurf_app = std::path::Path::new("/usr/bin/windsurf").exists();
    
    tools.push(DetectedTool {
        id: "windsurf".to_string(),
        name: "Windsurf".to_string(),
        installed: windsurf_app,
        config_path: None,
        can_auto_configure: false,
    });
    
    tools
}

// Configure Continue extension with ProxyPal endpoint
#[tauri::command]
fn configure_continue(state: State<AppState>) -> Result<String, String> {
    let config = state.config.lock().unwrap();
    let endpoint = format!("http://localhost:{}/v1", config.port);
    
    let home = dirs::home_dir().ok_or("Could not find home directory")?;
    let continue_dir = home.join(".continue");
    
    // Create directory if it doesn't exist
    std::fs::create_dir_all(&continue_dir).map_err(|e| e.to_string())?;
    
    let config_path = continue_dir.join("config.yaml");
    
    // Check if config already exists
    let existing_content = std::fs::read_to_string(&config_path).unwrap_or_default();
    
    // If config exists and already has ProxyPal, update it
    if existing_content.contains("ProxyPal") || existing_content.contains(&endpoint) {
        return Ok("Continue is already configured with ProxyPal".to_string());
    }
    
    // Create new config or append to existing
    let new_config = if existing_content.is_empty() {
        format!(r#"# Continue configuration - Auto-configured by ProxyPal
name: ProxyPal Config
version: 0.0.1
schema: v1

models:
  - name: ProxyPal (Auto-routed)
    provider: openai
    model: gpt-4
    apiKey: proxypal-local
    apiBase: {}
    roles:
      - chat
      - edit
      - apply
"#, endpoint)
    } else {
        // Append ProxyPal model to existing config
        format!(r#"{}
  # Added by ProxyPal
  - name: ProxyPal (Auto-routed)
    provider: openai
    model: gpt-4
    apiKey: proxypal-local
    apiBase: {}
    roles:
      - chat
      - edit
      - apply
"#, existing_content.trim_end(), endpoint)
    };
    
    std::fs::write(&config_path, new_config).map_err(|e| e.to_string())?;
    
    Ok(config_path.to_string_lossy().to_string())
}

// ============================================
// API Keys Management - CRUD operations via Management API
// ============================================

// API Key types matching Management API schema
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct GeminiApiKey {
    pub api_key: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub base_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub proxy_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub headers: Option<std::collections::HashMap<String, String>>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub excluded_models: Option<Vec<String>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ClaudeApiKey {
    pub api_key: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub base_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub proxy_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub headers: Option<std::collections::HashMap<String, String>>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub models: Option<Vec<String>>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub excluded_models: Option<Vec<String>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct CodexApiKey {
    pub api_key: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub base_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub proxy_url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub headers: Option<std::collections::HashMap<String, String>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct OpenAICompatibleApiKeyEntry {
    pub api_key: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub proxy_url: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct OpenAICompatibleModel {
    pub name: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub alias: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct OpenAICompatibleProvider {
    pub name: String,
    pub base_url: String,
    pub api_key_entries: Vec<OpenAICompatibleApiKeyEntry>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub models: Option<Vec<OpenAICompatibleModel>>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub headers: Option<std::collections::HashMap<String, String>>,
}

// Helper to build HTTP client for Management API
fn build_management_client() -> reqwest::Client {
    reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(10))
        .build()
        .unwrap_or_else(|_| reqwest::Client::new())
}

// Helper to get Management API base URL
fn get_management_url(port: u16, endpoint: &str) -> String {
    format!("http://127.0.0.1:{}/v0/management/{}", port, endpoint)
}

// Convert Management API kebab-case keys to camelCase for frontend
fn convert_api_key_response<T: serde::de::DeserializeOwned>(json: serde_json::Value) -> Result<Vec<T>, String> {
    // The Management API returns kebab-case, we need to convert
    let json_str = serde_json::to_string(&json).map_err(|e| e.to_string())?;
    // Replace kebab-case with camelCase for our structs
    let converted = json_str
        .replace("\"api-key\"", "\"apiKey\"")
        .replace("\"base-url\"", "\"baseUrl\"")
        .replace("\"proxy-url\"", "\"proxyUrl\"")
        .replace("\"excluded-models\"", "\"excludedModels\"")
        .replace("\"api-key-entries\"", "\"apiKeyEntries\"");
    serde_json::from_str(&converted).map_err(|e| e.to_string())
}

// Convert camelCase to kebab-case for Management API
fn convert_to_management_format<T: serde::Serialize>(data: &T) -> Result<serde_json::Value, String> {
    let json_str = serde_json::to_string(data).map_err(|e| e.to_string())?;
    let converted = json_str
        .replace("\"apiKey\"", "\"api-key\"")
        .replace("\"baseUrl\"", "\"base-url\"")
        .replace("\"proxyUrl\"", "\"proxy-url\"")
        .replace("\"excludedModels\"", "\"excluded-models\"")
        .replace("\"apiKeyEntries\"", "\"api-key-entries\"");
    serde_json::from_str(&converted).map_err(|e| e.to_string())
}

// Gemini API Keys
#[tauri::command]
async fn get_gemini_api_keys(state: State<'_, AppState>) -> Result<Vec<GeminiApiKey>, String> {
    let port = state.config.lock().unwrap().port;
    let url = get_management_url(port, "gemini-api-key");
    
    let client = build_management_client();
    let response = client
        .get(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .send()
        .await
        .map_err(|e| format!("Failed to fetch Gemini API keys: {}", e))?;
    
    if !response.status().is_success() {
        return Ok(Vec::new());
    }
    
    let json: serde_json::Value = response.json().await.map_err(|e| e.to_string())?;
    convert_api_key_response(json)
}

#[tauri::command]
async fn set_gemini_api_keys(state: State<'_, AppState>, keys: Vec<GeminiApiKey>) -> Result<(), String> {
    let port = state.config.lock().unwrap().port;
    let url = get_management_url(port, "gemini-api-key");
    
    let client = build_management_client();
    let body = convert_to_management_format(&keys)?;
    
    let response = client
        .put(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .json(&body)
        .send()
        .await
        .map_err(|e| format!("Failed to set Gemini API keys: {}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let text = response.text().await.unwrap_or_default();
        return Err(format!("Failed to set Gemini API keys: {} - {}", status, text));
    }
    
    Ok(())
}

#[tauri::command]
async fn add_gemini_api_key(state: State<'_, AppState>, key: GeminiApiKey) -> Result<(), String> {
    let mut keys = get_gemini_api_keys(state.clone()).await?;
    keys.push(key);
    set_gemini_api_keys(state, keys).await
}

#[tauri::command]
async fn delete_gemini_api_key(state: State<'_, AppState>, index: usize) -> Result<(), String> {
    let mut keys = get_gemini_api_keys(state.clone()).await?;
    if index >= keys.len() {
        return Err("Index out of bounds".to_string());
    }
    keys.remove(index);
    set_gemini_api_keys(state, keys).await
}

// Claude API Keys
#[tauri::command]
async fn get_claude_api_keys(state: State<'_, AppState>) -> Result<Vec<ClaudeApiKey>, String> {
    let port = state.config.lock().unwrap().port;
    let url = get_management_url(port, "claude-api-key");
    
    let client = build_management_client();
    let response = client
        .get(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .send()
        .await
        .map_err(|e| format!("Failed to fetch Claude API keys: {}", e))?;
    
    if !response.status().is_success() {
        return Ok(Vec::new());
    }
    
    let json: serde_json::Value = response.json().await.map_err(|e| e.to_string())?;
    convert_api_key_response(json)
}

#[tauri::command]
async fn set_claude_api_keys(state: State<'_, AppState>, keys: Vec<ClaudeApiKey>) -> Result<(), String> {
    let port = state.config.lock().unwrap().port;
    let url = get_management_url(port, "claude-api-key");
    
    let client = build_management_client();
    let body = convert_to_management_format(&keys)?;
    
    let response = client
        .put(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .json(&body)
        .send()
        .await
        .map_err(|e| format!("Failed to set Claude API keys: {}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let text = response.text().await.unwrap_or_default();
        return Err(format!("Failed to set Claude API keys: {} - {}", status, text));
    }
    
    Ok(())
}

#[tauri::command]
async fn add_claude_api_key(state: State<'_, AppState>, key: ClaudeApiKey) -> Result<(), String> {
    let mut keys = get_claude_api_keys(state.clone()).await?;
    keys.push(key);
    set_claude_api_keys(state, keys).await
}

#[tauri::command]
async fn delete_claude_api_key(state: State<'_, AppState>, index: usize) -> Result<(), String> {
    let mut keys = get_claude_api_keys(state.clone()).await?;
    if index >= keys.len() {
        return Err("Index out of bounds".to_string());
    }
    keys.remove(index);
    set_claude_api_keys(state, keys).await
}

// Codex API Keys
#[tauri::command]
async fn get_codex_api_keys(state: State<'_, AppState>) -> Result<Vec<CodexApiKey>, String> {
    let port = state.config.lock().unwrap().port;
    let url = get_management_url(port, "codex-api-key");
    
    let client = build_management_client();
    let response = client
        .get(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .send()
        .await
        .map_err(|e| format!("Failed to fetch Codex API keys: {}", e))?;
    
    if !response.status().is_success() {
        return Ok(Vec::new());
    }
    
    let json: serde_json::Value = response.json().await.map_err(|e| e.to_string())?;
    convert_api_key_response(json)
}

#[tauri::command]
async fn set_codex_api_keys(state: State<'_, AppState>, keys: Vec<CodexApiKey>) -> Result<(), String> {
    let port = state.config.lock().unwrap().port;
    let url = get_management_url(port, "codex-api-key");
    
    let client = build_management_client();
    let body = convert_to_management_format(&keys)?;
    
    let response = client
        .put(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .json(&body)
        .send()
        .await
        .map_err(|e| format!("Failed to set Codex API keys: {}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let text = response.text().await.unwrap_or_default();
        return Err(format!("Failed to set Codex API keys: {} - {}", status, text));
    }
    
    Ok(())
}

#[tauri::command]
async fn add_codex_api_key(state: State<'_, AppState>, key: CodexApiKey) -> Result<(), String> {
    let mut keys = get_codex_api_keys(state.clone()).await?;
    keys.push(key);
    set_codex_api_keys(state, keys).await
}

#[tauri::command]
async fn delete_codex_api_key(state: State<'_, AppState>, index: usize) -> Result<(), String> {
    let mut keys = get_codex_api_keys(state.clone()).await?;
    if index >= keys.len() {
        return Err("Index out of bounds".to_string());
    }
    keys.remove(index);
    set_codex_api_keys(state, keys).await
}

// OpenAI-Compatible Providers
#[tauri::command]
async fn get_openai_compatible_providers(state: State<'_, AppState>) -> Result<Vec<OpenAICompatibleProvider>, String> {
    let port = state.config.lock().unwrap().port;
    let url = get_management_url(port, "openai-compatibility");
    
    let client = build_management_client();
    let response = client
        .get(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .send()
        .await
        .map_err(|e| format!("Failed to fetch OpenAI-compatible providers: {}", e))?;
    
    if !response.status().is_success() {
        return Ok(Vec::new());
    }
    
    let json: serde_json::Value = response.json().await.map_err(|e| e.to_string())?;
    convert_api_key_response(json)
}

#[tauri::command]
async fn set_openai_compatible_providers(state: State<'_, AppState>, providers: Vec<OpenAICompatibleProvider>) -> Result<(), String> {
    let port = state.config.lock().unwrap().port;
    let url = get_management_url(port, "openai-compatibility");
    
    let client = build_management_client();
    let body = convert_to_management_format(&providers)?;
    
    let response = client
        .put(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .json(&body)
        .send()
        .await
        .map_err(|e| format!("Failed to set OpenAI-compatible providers: {}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let text = response.text().await.unwrap_or_default();
        return Err(format!("Failed to set OpenAI-compatible providers: {} - {}", status, text));
    }
    
    Ok(())
}

#[tauri::command]
async fn add_openai_compatible_provider(state: State<'_, AppState>, provider: OpenAICompatibleProvider) -> Result<(), String> {
    let mut providers = get_openai_compatible_providers(state.clone()).await?;
    providers.push(provider);
    set_openai_compatible_providers(state, providers).await
}

#[tauri::command]
async fn delete_openai_compatible_provider(state: State<'_, AppState>, index: usize) -> Result<(), String> {
    let mut providers = get_openai_compatible_providers(state.clone()).await?;
    if index >= providers.len() {
        return Err("Index out of bounds".to_string());
    }
    providers.remove(index);
    set_openai_compatible_providers(state, providers).await
}

// ============================================
// Auth Files Management - via Management API
// ============================================

// Auth file entry from Management API
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct AuthFile {
    pub id: String,
    pub name: String,
    pub provider: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub label: Option<String>,
    pub status: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub status_message: Option<String>,
    #[serde(default)]
    pub disabled: bool,
    #[serde(default)]
    pub unavailable: bool,
    #[serde(default)]
    pub runtime_only: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub source: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub path: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub size: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub modtime: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub email: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub account_type: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub account: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub created_at: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub updated_at: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub last_refresh: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub success_count: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub failure_count: Option<u64>,
}

// Get all auth files
#[tauri::command]
async fn get_auth_files(state: State<'_, AppState>) -> Result<Vec<AuthFile>, String> {
    let port = state.config.lock().unwrap().port;
    let url = get_management_url(port, "auth-files");
    
    let client = build_management_client();
    let response = client
        .get(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .send()
        .await
        .map_err(|e| format!("Failed to fetch auth files: {}", e))?;
    
    if !response.status().is_success() {
        return Ok(Vec::new());
    }
    
    let json: serde_json::Value = response.json().await.map_err(|e| e.to_string())?;
    
    // Management API returns { "files": [...] } or just an array
    let files_array = if let Some(files) = json.get("files") {
        files.clone()
    } else if json.is_array() {
        json
    } else {
        return Ok(Vec::new());
    };
    
    // Convert snake_case from API to camelCase for frontend
    let json_str = serde_json::to_string(&files_array).map_err(|e| e.to_string())?;
    let converted = json_str
        .replace("\"status_message\"", "\"statusMessage\"")
        .replace("\"runtime_only\"", "\"runtimeOnly\"")
        .replace("\"account_type\"", "\"accountType\"")
        .replace("\"created_at\"", "\"createdAt\"")
        .replace("\"updated_at\"", "\"updatedAt\"")
        .replace("\"last_refresh\"", "\"lastRefresh\"")
        .replace("\"success_count\"", "\"successCount\"")
        .replace("\"failure_count\"", "\"failureCount\"");
    
    serde_json::from_str(&converted).map_err(|e| e.to_string())
}

// Upload auth file
#[tauri::command]
async fn upload_auth_file(state: State<'_, AppState>, file_path: String, provider: String) -> Result<(), String> {
    let port = state.config.lock().unwrap().port;
    let url = get_management_url(port, "auth-files");
    
    // Read file content
    let content = std::fs::read(&file_path)
        .map_err(|e| format!("Failed to read file: {}", e))?;
    
    // Get filename from path
    let filename = std::path::Path::new(&file_path)
        .file_name()
        .and_then(|n| n.to_str())
        .unwrap_or("auth.json")
        .to_string();
    
    let client = build_management_client();
    
    // Create multipart form
    let part = reqwest::multipart::Part::bytes(content)
        .file_name(filename.clone())
        .mime_str("application/json")
        .map_err(|e| e.to_string())?;
    
    let form = reqwest::multipart::Form::new()
        .text("provider", provider)
        .text("filename", filename)
        .part("file", part);
    
    let response = client
        .post(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .multipart(form)
        .send()
        .await
        .map_err(|e| format!("Failed to upload auth file: {}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let text = response.text().await.unwrap_or_default();
        return Err(format!("Failed to upload auth file: {} - {}", status, text));
    }
    
    Ok(())
}

// Delete auth file
#[tauri::command]
async fn delete_auth_file(state: State<'_, AppState>, file_id: String) -> Result<(), String> {
    let port = state.config.lock().unwrap().port;
    let url = format!("{}/{}", get_management_url(port, "auth-files"), file_id);
    
    let client = build_management_client();
    let response = client
        .delete(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .send()
        .await
        .map_err(|e| format!("Failed to delete auth file: {}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let text = response.text().await.unwrap_or_default();
        return Err(format!("Failed to delete auth file: {} - {}", status, text));
    }
    
    Ok(())
}

// Toggle auth file enabled/disabled
#[tauri::command]
async fn toggle_auth_file(state: State<'_, AppState>, file_id: String, disabled: bool) -> Result<(), String> {
    let port = state.config.lock().unwrap().port;
    let url = format!("{}/{}/disabled", get_management_url(port, "auth-files"), file_id);
    
    let client = build_management_client();
    let response = client
        .put(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .json(&serde_json::json!({ "value": disabled }))
        .send()
        .await
        .map_err(|e| format!("Failed to toggle auth file: {}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let text = response.text().await.unwrap_or_default();
        return Err(format!("Failed to toggle auth file: {} - {}", status, text));
    }
    
    Ok(())
}

// Download auth file - returns path to temp file
#[tauri::command]
async fn download_auth_file(state: State<'_, AppState>, file_id: String, filename: String) -> Result<String, String> {
    let port = state.config.lock().unwrap().port;
    let url = format!("{}?id={}", get_management_url(port, "auth-files/download"), file_id);
    
    let client = build_management_client();
    let response = client
        .get(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .send()
        .await
        .map_err(|e| format!("Failed to download auth file: {}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let text = response.text().await.unwrap_or_default();
        return Err(format!("Failed to download auth file: {} - {}", status, text));
    }
    
    let bytes = response.bytes().await.map_err(|e| e.to_string())?;
    
    // Save to downloads directory
    let downloads_dir = dirs::download_dir()
        .unwrap_or_else(|| dirs::home_dir().unwrap_or_default());
    
    let dest_path = downloads_dir.join(&filename);
    std::fs::write(&dest_path, &bytes)
        .map_err(|e| format!("Failed to save file: {}", e))?;
    
    Ok(dest_path.to_string_lossy().to_string())
}

// Delete all auth files
#[tauri::command]
async fn delete_all_auth_files(state: State<'_, AppState>) -> Result<(), String> {
    let port = state.config.lock().unwrap().port;
    let url = get_management_url(port, "auth-files");
    
    let client = build_management_client();
    let response = client
        .delete(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .send()
        .await
        .map_err(|e| format!("Failed to delete all auth files: {}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let text = response.text().await.unwrap_or_default();
        return Err(format!("Failed to delete all auth files: {} - {}", status, text));
    }
    
    Ok(())
}

// ============================================================================
// Log Viewer Commands
// ============================================================================

// Log entry structure
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct LogEntry {
    pub timestamp: String,
    pub level: String,
    pub message: String,
}

// API response structure for logs
#[derive(Debug, Clone, Deserialize)]
#[serde(rename_all = "kebab-case")]
struct LogsApiResponse {
    #[serde(default)]
    #[allow(dead_code)]
    latest_timestamp: Option<i64>,
    #[serde(default)]
    #[allow(dead_code)]
    line_count: Option<u32>,
    #[serde(default)]
    lines: Vec<String>,
}

// Get logs from the proxy server
#[tauri::command]
async fn get_logs(state: State<'_, AppState>, lines: Option<u32>) -> Result<Vec<LogEntry>, String> {
    let port = state.config.lock().unwrap().port;
    let lines_param = lines.unwrap_or(500);
    let url = format!("{}?lines={}", get_management_url(port, "logs"), lines_param);
    
    let client = build_management_client();
    let response = client
        .get(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .send()
        .await
        .map_err(|e| format!("Failed to get logs: {}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let text = response.text().await.unwrap_or_default();
        return Err(format!("Failed to get logs: {} - {}", status, text));
    }
    
    // Parse JSON response
    let api_response: LogsApiResponse = response
        .json()
        .await
        .map_err(|e| format!("Failed to parse logs response: {}", e))?;
    
    // Parse each line into a LogEntry
    let entries: Vec<LogEntry> = api_response
        .lines
        .iter()
        .filter(|line| !line.is_empty())
        .map(|line| parse_log_line(line))
        .collect();
    
    Ok(entries)
}

// Parse a log line into a LogEntry struct
// Expected formats from CLIProxyAPI:
// - "[2025-12-02 22:12:52] [info] [gin_logger.go:58] message"
// - "[2025-12-02 22:12:52] [info] message"  
// - "2024-01-15T10:30:45.123Z [INFO] message"
fn parse_log_line(line: &str) -> LogEntry {
    let line = line.trim();
    
    // Format: [timestamp] [level] [source] message
    // or: [timestamp] [level] message
    if line.starts_with('[') {
        let mut parts = Vec::new();
        let mut current_start = 0;
        let mut in_bracket = false;
        
        for (i, c) in line.char_indices() {
            if c == '[' && !in_bracket {
                in_bracket = true;
                current_start = i + 1;
            } else if c == ']' && in_bracket {
                in_bracket = false;
                parts.push(&line[current_start..i]);
                current_start = i + 1;
            }
        }
        
        // Get the message (everything after the last bracket)
        let message_start = line.rfind(']').map(|i| i + 1).unwrap_or(0);
        let message = line[message_start..].trim();
        
        if parts.len() >= 2 {
            let timestamp = parts[0].to_string();
            let level = parts[1].to_uppercase();
            
            return LogEntry {
                timestamp,
                level: normalize_log_level(&level),
                message: message.to_string(),
            };
        }
    }
    
    // Try ISO timestamp format: "2024-01-15T10:30:45.123Z [INFO] message"
    if line.len() > 20 && (line.chars().nth(4) == Some('-') || line.chars().nth(10) == Some('T')) {
        if let Some(bracket_start) = line.find('[') {
            if let Some(bracket_end) = line[bracket_start..].find(']') {
                let timestamp = line[..bracket_start].trim().to_string();
                let level = line[bracket_start + 1..bracket_start + bracket_end].to_string();
                let message = line[bracket_start + bracket_end + 1..].trim().to_string();
                
                return LogEntry {
                    timestamp,
                    level: normalize_log_level(&level),
                    message,
                };
            }
        }
    }
    
    // Try "LEVEL: message" format
    for level in &["ERROR", "WARN", "INFO", "DEBUG", "TRACE"] {
        if line.to_uppercase().starts_with(level) {
            let rest = &line[level.len()..];
            if rest.starts_with(':') || rest.starts_with(' ') {
                return LogEntry {
                    timestamp: String::new(),
                    level: level.to_string(),
                    message: rest.trim_start_matches(|c| c == ':' || c == ' ').to_string(),
                };
            }
        }
    }
    
    // Default: plain text as INFO
    LogEntry {
        timestamp: String::new(),
        level: "INFO".to_string(),
        message: line.to_string(),
    }
}

// Normalize log level to standard format
fn normalize_log_level(level: &str) -> String {
    match level.to_uppercase().as_str() {
        "ERROR" | "ERR" | "E" => "ERROR".to_string(),
        "WARN" | "WARNING" | "W" => "WARN".to_string(),
        "INFO" | "I" => "INFO".to_string(),
        "DEBUG" | "DBG" | "D" => "DEBUG".to_string(),
        "TRACE" | "T" => "TRACE".to_string(),
        _ => level.to_uppercase(),
    }
}

// Clear all logs
#[tauri::command]
async fn clear_logs(state: State<'_, AppState>) -> Result<(), String> {
    let port = state.config.lock().unwrap().port;
    let url = get_management_url(port, "logs");
    
    let client = build_management_client();
    let response = client
        .delete(&url)
        .header("X-Management-Key", "proxypal-mgmt-key")
        .send()
        .await
        .map_err(|e| format!("Failed to clear logs: {}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let text = response.text().await.unwrap_or_default();
        return Err(format!("Failed to clear logs: {} - {}", status, text));
    }
    
    Ok(())
}

// Get setup instructions for a specific tool
#[tauri::command]
fn get_tool_setup_info(tool_id: String, state: State<AppState>) -> Result<serde_json::Value, String> {
    let config = state.config.lock().unwrap();
    let endpoint = format!("http://localhost:{}/v1", config.port);
    
    let info = match tool_id.as_str() {
        "cursor" => serde_json::json!({
            "name": "Cursor",
            "logo": "/logos/cursor.svg",
            "canAutoConfigure": false,
            "note": "Cursor doesn't support custom API base URLs. Use your connected providers' API keys directly in Cursor settings.",
            "steps": [
                {
                    "title": "Open Cursor Settings",
                    "description": "Press Cmd+, (Mac) or Ctrl+, (Windows) and go to 'Models'"
                },
                {
                    "title": "Add API Keys",
                    "description": "Enter your API keys for Claude, OpenAI, or other providers directly"
                }
            ]
        }),
        "continue" => serde_json::json!({
            "name": "Continue",
            "logo": "/logos/continue.svg",
            "canAutoConfigure": true,
            "steps": [
                {
                    "title": "Auto-Configure",
                    "description": "Click the button below to automatically configure Continue"
                },
                {
                    "title": "Or Manual Setup",
                    "description": "Open ~/.continue/config.yaml and add:"
                }
            ],
            "manualConfig": format!(r#"models:
  - name: ProxyPal
    provider: openai
    model: gpt-4
    apiKey: proxypal-local
    apiBase: {}"#, endpoint),
            "endpoint": endpoint
        }),
        "cline" => serde_json::json!({
            "name": "Cline",
            "logo": "/logos/cline.svg",
            "canAutoConfigure": false,
            "steps": [
                {
                    "title": "Open Cline Settings",
                    "description": "Click the Cline icon in VS Code sidebar, then click the gear icon"
                },
                {
                    "title": "Select API Provider",
                    "description": "Choose 'OpenAI Compatible' from the provider dropdown"
                },
                {
                    "title": "Set Base URL",
                    "description": "Enter the ProxyPal endpoint:",
                    "copyable": endpoint.clone()
                },
                {
                    "title": "Set API Key",
                    "description": "Enter: proxypal-local",
                    "copyable": "proxypal-local".to_string()
                },
                {
                    "title": "Select Model",
                    "description": "Enter any model name (e.g., gpt-4, claude-3-sonnet)"
                }
            ],
            "endpoint": endpoint
        }),
        "windsurf" => serde_json::json!({
            "name": "Windsurf",
            "logo": "/logos/windsurf.svg",
            "canAutoConfigure": false,
            "note": "Windsurf doesn't support custom API endpoints. It only supports direct API keys for Claude models.",
            "steps": [
                {
                    "title": "Not Supported",
                    "description": "Windsurf routes all requests through Codeium servers and doesn't allow custom endpoints."
                }
            ]
        }),
        _ => return Err(format!("Unknown tool: {}", tool_id)),
    };
    
    Ok(info)
}

#[cfg_attr(mobile, tauri::mobile_entry_point)]
pub fn run() {
    // Load persisted config and auth
    let config = load_config();
    let auth = load_auth_status();

    let app_state = AppState {
        proxy_status: Mutex::new(ProxyStatus::default()),
        auth_status: Mutex::new(auth),
        config: Mutex::new(config),
        pending_oauth: Mutex::new(None),
        proxy_process: Mutex::new(None),
    };

    tauri::Builder::default()
        .plugin(tauri_plugin_opener::init())
        .plugin(tauri_plugin_shell::init())
        .plugin(tauri_plugin_deep_link::init())
        .plugin(tauri_plugin_notification::init())
        .plugin(tauri_plugin_dialog::init())
        .plugin(tauri_plugin_single_instance::init(|app, args, _cwd| {
            // Handle deep links when app is already running
            let urls: Vec<url::Url> = args
                .iter()
                .filter_map(|arg| url::Url::parse(arg).ok())
                .collect();
            if !urls.is_empty() {
                handle_deep_link(app, urls);
            }

            // Show existing window
            if let Some(window) = app.get_webview_window("main") {
                let _ = window.unminimize();
                let _ = window.show();
                let _ = window.set_focus();
            }
        }))
        .manage(app_state)
        .setup(|app| {
            // Setup system tray
            #[cfg(desktop)]
            setup_tray(app)?;

            // Register deep link handler for when app is already running
            #[cfg(desktop)]
            {
                use tauri_plugin_deep_link::DeepLinkExt;
                let handle = app.handle().clone();
                app.deep_link().on_open_url(move |event| {
                    let urls: Vec<url::Url> = event.urls().to_vec();
                    if !urls.is_empty() {
                        handle_deep_link(&handle, urls);
                    }
                });
            }

            Ok(())
        })
        .invoke_handler(tauri::generate_handler![
            get_proxy_status,
            start_proxy,
            stop_proxy,
            get_auth_status,
            refresh_auth_status,
            open_oauth,
            poll_oauth_status,
            complete_oauth,
            disconnect_provider,
            import_vertex_credential,
            get_config,
            save_config,
            check_provider_health,
            detect_ai_tools,
            configure_continue,
            get_tool_setup_info,
            detect_cli_agents,
            configure_cli_agent,
            get_shell_profile_path,
            append_to_shell_profile,
            get_usage_stats,
            get_request_history,
            add_request_to_history,
            clear_request_history,
            test_agent_connection,
            get_available_models,
            // API Keys Management
            get_gemini_api_keys,
            set_gemini_api_keys,
            add_gemini_api_key,
            delete_gemini_api_key,
            get_claude_api_keys,
            set_claude_api_keys,
            add_claude_api_key,
            delete_claude_api_key,
            get_codex_api_keys,
            set_codex_api_keys,
            add_codex_api_key,
            delete_codex_api_key,
            get_openai_compatible_providers,
            set_openai_compatible_providers,
            add_openai_compatible_provider,
            delete_openai_compatible_provider,
            // Auth Files Management
            get_auth_files,
            upload_auth_file,
            delete_auth_file,
            toggle_auth_file,
            download_auth_file,
            delete_all_auth_files,
            // Log Viewer
            get_logs,
            clear_logs,
        ])
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}
